# üèõÔ∏è Arquitectura del Proyecto de An√°lisis Filos√≥fico

Este documento describe la arquitectura de alto nivel del sistema de an√°lisis de textos filos√≥ficos, detallando sus componentes principales, el flujo de datos y las decisiones de dise√±o.

## 1. Filosof√≠a de Dise√±o

El proyecto est√° dise√±ado siguiendo principios de **modularidad y especializaci√≥n**. Cada componente tiene una responsabilidad √∫nica y bien definida, lo que facilita las pruebas, el mantenimiento y la extensi√≥n del sistema. La arquitectura separa claramente:

- **El motor de an√°lisis (`core`)**: La l√≥gica cient√≠fica para procesar textos.
- **La capa de visualizaci√≥n (`visualization`)**: La generaci√≥n de datos para los reportes interactivos.
- **La capa de interfaz (`cli`, `notebooks`)**: Los puntos de entrada para interactuar con el sistema.

## 2. Estructura de Directorios

La organizaci√≥n del proyecto refleja esta filosof√≠a:

```
philosophical-text-analysis/
‚îú‚îÄ‚îÄ config/                 # Archivos de configuraci√≥n (ej. main.yaml)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Textos originales (.txt)
‚îÇ   ‚îî‚îÄ‚îÄ processed/          # (Opcional) Datos intermedios limpios
‚îú‚îÄ‚îÄ notebooks/              # Cuadernos de Jupyter para demostraci√≥n y experimentaci√≥n
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îî‚îÄ‚îÄ visualizations/     # Salidas finales: HTML interactivos y datos JSON
‚îú‚îÄ‚îÄ src/philosophical_analysis/
‚îÇ   ‚îú‚îÄ‚îÄ core/               # L√≥gica principal de an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ visualization/      # Generaci√≥n de datos para visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ cli.py              # Interfaz de l√≠nea de comandos
‚îú‚îÄ‚îÄ tests/                  # Pruebas unitarias y de integraci√≥n
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ ROADMAP.md
‚îî‚îÄ‚îÄ ARCHITECTURE.md         # Este archivo
```

## 3. Flujo de Datos

El sistema procesa los datos a trav√©s de un pipeline bien definido:

  <!-- Placeholder para un diagrama futuro -->

1.  **Entrada de Datos**: El proceso se inicia con los textos crudos (`.txt`) ubicados en `data/raw/`.

2.  **An√°lisis Integrado**: El `IntegratedPhilosophicalAnalyzer` orquesta el an√°lisis. Invoca secuencialmente a los siguientes componentes del `core`:
    *   `AdvancedPOSAnalyzer`: Realiza un an√°lisis sint√°ctico para extraer caracter√≠sticas como la frecuencia de determinantes y la longitud de las frases.
    *   `EnhancedCoherenceAnalyzer`: Modela el texto usando LSA (An√°lisis Sem√°ntico Latente) para calcular la coherencia sem√°ntica de primer y segundo orden.
    *   `ConvexHullClassifier`: Utiliza las caracter√≠sticas extra√≠das para clasificar el texto, por ejemplo, como "coherente" o "incoherente", bas√°ndose en un clasificador de casco convexo.

3.  **Resultados del An√°lisis**: El analizador genera un `DataFrame` de Pandas con todas las m√©tricas calculadas para cada texto. Este `DataFrame` puede ser guardado como un archivo `.csv`.

4.  **Generaci√≥n de Visualizaciones**: El `VisualizationGenerator` toma el `DataFrame` de resultados y los textos originales para producir los datos de visualizaci√≥n:
    *   Invoca al `SemanticNetworkGenerator` para construir un grafo de conceptos clave y sus relaciones.
    *   Calcula estad√≠sticas comparativas y datos temporales para el dashboard.

5.  **Salida Final**: Los datos generados se guardan en `reports/visualizations/` como:
    *   **Archivos JSON**: Datos limpios y estructurados (ej. `dashboard_data.json`, `network_data.json`).
    *   **Archivos HTML**: P√°ginas web interactivas que cargan los datos JSON y los renderizan usando librer√≠as de JavaScript como D3.js o Plotly.

## 4. Componentes Principales

### M√≥dulos del `core`

-   **`integrated_analyzer.py`**: El orquestador principal. Su rol es integrar los resultados de los dem√°s analizadores en un pipeline coherente.
-   **`pos_analyzer.py`**: Especializado en el an√°lisis de Part-of-Speech (POS) y la extracci√≥n de m√©tricas sint√°cticas definidas en el paper de investigaci√≥n.
-   **`enhanced_coherence.py`**: Implementa los algoritmos de coherencia sem√°ntica, incluyendo LSA y el seguimiento temporal.
-   **`convex_hull.py`**: Contiene la l√≥gica del clasificador basado en casco convexo, incluyendo el entrenamiento (leave-one-out) y la predicci√≥n.

### M√≥dulos de `visualization`

-   **`generator.py`**: El orquestador de la visualizaci√≥n. Prepara los datos para todos los componentes visuales (dashboard, gr√°ficos temporales) y gestiona la actualizaci√≥n de los archivos HTML.
-   **`semantic_network.py`**: Un m√≥dulo especializado que se enfoca exclusivamente en extraer conceptos filos√≥ficos de un texto y construir una red de relaciones basada en su co-ocurrencia y similitud sem√°ntica.

## 5. Decisiones de Dise√±o Clave

-   **Configuraci√≥n sobre C√≥digo**: Se utiliza un archivo `config/main.yaml` para definir par√°metros clave (ej. n√∫mero de componentes LSA, rutas de archivos), permitiendo modificar el comportamiento del sistema sin cambiar el c√≥digo.
-   **Tests Internos en M√≥dulos**: M√≥dulos complejos como `semantic_network.py` incluyen una funci√≥n `test_*()` dentro del propio archivo. Esto permite una verificaci√≥n r√°pida y aislada de su funcionalidad ejecutando `python -m src.philosophical_analysis.visualization.semantic_network`.
-   **Separaci√≥n de Datos y Presentaci√≥n**: La capa de visualizaci√≥n genera archivos JSON desacoplados de los HTML. Esto permite que el frontend (HTML/JS) y el backend (Python) evolucionen de forma independiente. Un equipo de frontend podr√≠a, por ejemplo, redise√±ar los reportes sin necesidad de tocar el c√≥digo Python.
